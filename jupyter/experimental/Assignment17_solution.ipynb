{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 17: Kiểm tra đạo văn\n",
    "\n",
    "Tổng quan: Ở bài tập này chúng ta sẽ lần lượt thực hành các bước để xây dựng một ứng dụng kiểm tra đạo văn sử dụng một mô hình pre-trained word2vec. \n",
    "\n",
    "- Dữ liệu được lưu trong hai file: en_source_data.txt chứa văn bản cần kiểm tra, en_target_data.txt chứa các văn bản đối chiếu.\n",
    "- Bài tập yêu cầu các kiến thức về lập trình Python với các thư viện: gensim (để load word2vec model), numpy (tính similarity). Ngoài ra chúng ta sử dụng một pre-trained word2vec model (sử dụng [Google's pre-trained word2vec model](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu hỏi 1: khảo sát tập dữ liệu\n",
    "Hãy lập trình đoạn chương trình dưới đây để khảo sát về số lượng và quan sát một vài ví dụ về bộ dữ liệu.\n",
    "\n",
    "Gợi ý: \n",
    "- Đọc tài liệu cần kiểm tra, từ file \"./en_source_data.txt\", lưu vào biến source_doc. \n",
    "- Đọc các tài liệu đối chiếu từ file \"./en_target_data.txt\", rồi lưu vào biến target_docs (kiểu list, mỗi doc là một phần tử trong list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_doc:\n",
      " Over the long term, the durability of attitudes toward Trump spotlights the likelihood of a widening rift between two Americas fundamentally diverging in both their exposure to and attitudes about such fundamental dynamics as the nation's growing racial and religious diversity, rising demands for greater racial equality, changing gender roles and the transition from an industrial to an information age economy.\n",
      "\n",
      "target_doc_num: 23\n"
     ]
    }
   ],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "\n",
    "f = open(\"en_source_data.txt\", \"r\")\n",
    "source_doc = f.readline()\n",
    "f. close()\n",
    "\n",
    "f = open(\"en_target_data.txt\", \"r\")\n",
    "target_docs = f.readlines()\n",
    "f. close()\n",
    "\n",
    "#### YOUR CODE HERE ####\n",
    "print(\"source_doc:\\n\",source_doc)\n",
    "print(\"target_doc_num:\", len(target_docs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu hỏi 2: Xây dựng một class cho việc tính document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocSim:\n",
    "    def __init__(self, w2v_model, stopwords=None):\n",
    "        self.w2v_model = w2v_model\n",
    "        self.stopwords = stopwords if stopwords is not None else []\n",
    "\n",
    "    \"\"\"\n",
    "    Câu hỏi 2.1:\n",
    "    Xác định giá trị các vectors cho từng từ trong document. Đầu tiên, tiền\n",
    "    xử lý tài liệu đầu vào. Sau đó, với mỗi từ ta tính word2vec cho từng từ\n",
    "    trong văn bản. Cuối cùng, ta tính trung bình các vectors của các từ\n",
    "    trong văn bản đó. Câu hỏi trong bài tập này là tính giá trị embedding\n",
    "    của từng từ (cú pháp: self.w2v_model[<từ_cần_tính>]), rồi gán vào biến vec\n",
    "    \"\"\"\n",
    "    def vectorize(self, doc: str) -> np.ndarray:\n",
    "        doc = doc.lower()\n",
    "        words = [w for w in doc.split(\" \") if w not in self.stopwords]\n",
    "        word_vecs = []\n",
    "        for word in words:\n",
    "            try:\n",
    "                #### YOUR CODE HERE ####\n",
    "                \n",
    "                vec = self.w2v_model[word]\n",
    "                \n",
    "                #### YOUR CODE HERE ####\n",
    "                word_vecs.append(vec)\n",
    "            except KeyError:\n",
    "                # Ignore, if the word doesn't exist in the vocabulary\n",
    "                pass\n",
    "\n",
    "        vector = np.mean(word_vecs, axis=0)\n",
    "        return vector\n",
    "\n",
    "    def _cosine_sim(self, vecA, vecB):\n",
    "        \"\"\"\n",
    "        Câu hỏi 2.2:\n",
    "        Tính cosine similarity giữa hai vectors (vecA, vecB)\n",
    "        \"\"\"\n",
    "        #### YOUR CODE HERE ####\n",
    "        \n",
    "        csim = np.dot(vecA, vecB) / (np.linalg.norm(vecA) * np.linalg.norm(vecB))\n",
    "        \n",
    "        #### YOUR CODE HERE ####\n",
    "        \n",
    "        if np.isnan(np.sum(csim)):\n",
    "            return 0\n",
    "        return csim\n",
    "        \"\"\"\n",
    "        Câu hỏi 2.3:\n",
    "        Hàm dưới dùng để tính giá trị similarity giữa hai tài liệu cần\n",
    "        so sánh. Hoàn thành việc tính độ tương tự giữa hai vectors (source_vec,\n",
    "        target_vec)\n",
    "        Gợi ý: dùng hàm _cosine_sim()\n",
    "        \"\"\"\n",
    "    def calculate_similarity(self, source_doc, target_docs=None, threshold=0.9):\n",
    "        \"\"\"Calculates & returns similarity scores between given source document & all\n",
    "        the target documents.\"\"\"\n",
    "        if not target_docs:\n",
    "            return []\n",
    "\n",
    "        if isinstance(target_docs, str):\n",
    "            target_docs = [target_docs]\n",
    "\n",
    "        source_vec = self.vectorize(source_doc)\n",
    "        results = []\n",
    "        for doc in target_docs:\n",
    "            target_vec = self.vectorize(doc)\n",
    "            #### YOUR CODE HERE ####\n",
    "            \n",
    "            sim_score = self._cosine_sim(source_vec, target_vec)\n",
    "            \n",
    "            #### YOUR CODE HERE ####\n",
    "            if sim_score > threshold:\n",
    "                results.append({\"score\": sim_score, \"doc\": doc})\n",
    "            # Sort results by score in desc order\n",
    "            results.sort(key=lambda k: k[\"score\"], reverse=True)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu hỏi 3: Tạo đối tượng\n",
    "Sau khi đã tạo xong lớp để tính toán similarity giữa các docs (DocSim), chúng ta đi tạo đối tượng cho lớp trên:\n",
    "\n",
    "- Load pre-trained word embedding model\n",
    "- Tạo danh sách từ dừng\n",
    "- Sau cùng là tạo đối tượng cho lớp DocSim\n",
    "\n",
    "Gợi ý: tạo đối tượng ds của lớp DocSim() với hai tham số là model và stopwords=stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenews_model_path = '/Users/TheHV/Downloads/GoogleNews-vectors-negative300.bin'\n",
    "stopwords_path = './stopwords_en.txt'\n",
    "model = KeyedVectors.load_word2vec_format(googlenews_model_path, binary=True)\n",
    "with open(stopwords_path, 'r') as fh:\n",
    "    stopwords = fh.read().split(\",\")\n",
    "#### YOUR CODE HERE ####\n",
    "\n",
    "ds = DocSim(model,stopwords=stopwords)\n",
    "\n",
    "#### YOUR CODE HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu hỏi 4: Kiểm tra đạo văn cho một doc mới\n",
    "Gợi ý: Sử dụng hàm ds.calculate_similarity() để tính độ tương tự gữa tài liệu cần kiểm tra source_doc, và các tài liệu đối chiếu (target_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 1.0, 'doc': \"Over the long term, the durability of attitudes toward Trump spotlights the likelihood of a widening rift between two Americas fundamentally diverging in both their exposure to and attitudes about such fundamental dynamics as the nation's growing racial and religious diversity, rising demands for greater racial equality, changing gender roles and the transition from an industrial to an information age economy.\\n\"}]\n"
     ]
    }
   ],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "\n",
    "sim_scores = ds.calculate_similarity(source_doc, target_docs)\n",
    "\n",
    "#### YOUR CODE HERE ####\n",
    "print(sim_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
